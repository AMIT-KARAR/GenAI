{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHkfwEPUJFpNVeVmEPmKSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMIT-KARAR/GenAI/blob/main/code_play.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ew5Q7cSqhfO",
        "outputId": "ae2843a9-cc45-4138-b483-2d3951eb9eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Python\n"
          ]
        }
      ],
      "source": [
        "print (\"Hello Python\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_SJbCSArhqq",
        "outputId": "c8705836-83af-4f73-c25c-0fac333c1b31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\" Hi! This is amit karar. I am, Learning NLP through Python.\n",
        "I am using cllob for pytyhon code. This will'be help, me to access code in cloud.\n",
        "Practice regularly to became expart in NLP. Thnks !\"\"\""
      ],
      "metadata": {
        "id": "gzjl30WCtpuB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tdko7TgctqKU",
        "outputId": "b95cb9fb-b3b7-4f21-cca9-0ec813e0b5f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi! This is amit karar. I am, Learning NLP through Python.\\nI am using cllob for pytyhon code. This will'be help, me to access code in cloud. \\nPractice regularly to became expart in NLP. Thnks !\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmtzGw_ku5LE",
        "outputId": "af86a54c-5625-42e3-96a5-ecf969102b4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hi! This is amit karar. I am, Learning NLP through Python.\n",
            "I am using cllob for pytyhon code. This will'be help, me to access code in cloud. \n",
            "Practice regularly to became expart in NLP. Thnks !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Tokenization\n",
        "## Paragraph --> Sentence\n",
        "\n",
        "##  Tokenization\n",
        "## Sentence-->paragraphs\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JBavqSBXvDKC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents=sent_tokenize(corpus)\n",
        "\n",
        "type (documents)\n",
        "\n",
        "print (documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC1grCTewZJn",
        "outputId": "3fc8bce9-d767-48e5-8a71-af7548d53ed2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Hi!', 'This is amit karar.', 'I am, Learning NLP through Python.', 'I am using cllob for pytyhon code.', \"This will'be help, me to access code in cloud.\", 'Practice regularly to became expart in NLP.', 'Thnks !']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentance in documents:\n",
        "  print (sentance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9MtTmloyxdz",
        "outputId": "86797de4-9816-40a5-e2db-b75b8f7db6d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hi!\n",
            "This is amit karar.\n",
            "I am, Learning NLP through Python.\n",
            "I am using cllob for pytyhon code.\n",
            "This will'be help, me to access code in cloud.\n",
            "Practice regularly to became expart in NLP.\n",
            "Thnks !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenizantion\n",
        "## Paragraph ---> Words\n",
        "## Sentance ----> Words\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "word=word_tokenize(corpus)"
      ],
      "metadata": {
        "id": "qoWBFjrVy_BV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type (word)\n",
        "print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTnKGk-v0Nk-",
        "outputId": "dad82992-67b2-4ad5-e64f-4422ccb390b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', '!', 'This', 'is', 'amit', 'karar', '.', 'I', 'am', ',', 'Learning', 'NLP', 'through', 'Python', '.', 'I', 'am', 'using', 'cllob', 'for', 'pytyhon', 'code', '.', 'This', \"will'be\", 'help', ',', 'me', 'to', 'access', 'code', 'in', 'cloud', '.', 'Practice', 'regularly', 'to', 'became', 'expart', 'in', 'NLP', '.', 'Thnks', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "# Corrected way to use wordpunct_tokenize:\n",
        "# Option 1: Use the function directly\n",
        "wordpunct_tokens = wordpunct_tokenize(corpus)\n",
        "\n",
        "# Option 2: Instantiate the tokenizer and then call tokenize\n",
        "# tokenizer = WordPunctTokenizer()\n",
        "# wordpunct_tokens = tokenizer.tokenize(corpus)\n",
        "\n",
        "print(wordpunct_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTMWZ3mu1Ut7",
        "outputId": "92e57118-c310-4af6-e443-d906ca269f62"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', '!', 'This', 'is', 'amit', 'karar', '.', 'I', 'am', ',', 'Learning', 'NLP', 'through', 'Python', '.', 'I', 'am', 'using', 'cllob', 'for', 'pytyhon', 'code', '.', 'This', 'will', \"'\", 'be', 'help', ',', 'me', 'to', 'access', 'code', 'in', 'cloud', '.', 'Practice', 'regularly', 'to', 'became', 'expart', 'in', 'NLP', '.', 'Thnks', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yo-IlqpB2CIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}